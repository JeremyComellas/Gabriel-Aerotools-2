{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vale, según los tests que se han hecho por ahora, se identifica que el método es bastante consistente en cuanto a que si lo runneas varias veces con los mismos parámetros, te da los mismos valores y resultados. esto se ha comprobado en los resultados de los runs:\n",
    "\n",
    "Data_processed\\main\\Analysis_Images_6_6_SIFT_2\n",
    "\n",
    "Data_processed\\main\\Analysis_Images_6_6_SIFT_3\n",
    "\n",
    "Data_processed\\main\\Analysis_Images_6_6_SIFT_4\n",
    "\n",
    "en las que los resultados y gráficos son bastante constantes. Por ahora se va a proceder a elegir el mejor set_up para el SIFT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados.\n",
    "\n",
    "Analizando los resultados obtenidos de las tres carpetas superiores (images6_6_SIFT) se observa que se puede analizar correctamente el efecto de ir variando los diferentes parámetros, y el método de encontrar parámetros optimos es adecuado. \n",
    "\n",
    "Lleva bastante trabajo ir analizando los efectos de cada parámtero pero se identifican trends generales. \n",
    "\n",
    "A medida que se va cambiando el contrast threshold, se va reduciendo poco a poco la cantidad de matches, pero van aumentando otros parámetros. \n",
    "\n",
    "Por ejemplo, el Average_X tiende hacia una asintota horizontal, la cual es positivamente \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Utilizar los minimos valores de start_x en las features del suelo, para encontrar los puntos que identifican claramente cuanto translación hay entre una imagen y otra, Y mediante este método, clasificar entre imagenes que se trasladan poco, e imágenes que se trasladan mucho*\n",
    "\n",
    "*A partir de esto, demonstrar que mi método funciona correctamente para las imágenes en las que se ha desplazado poco el dron, y demostrar cómo no funciona en las que se desplaza mucho, puesto que se confunde*\n",
    "\n",
    "*Con esto, argumentar que se debería implementar la manera que haga fotos con más frecuencia* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUCKING INTERESTING\n",
    "\n",
    "\n",
    "Okay, look at edgeThreshold variation of 7_7. (*(Data_processed/main/Analysis_Images_7_7_SIFT/output_edgeThreshold_2024-08-13_20-36-54)*) look at the graph of average_x. Go to the last image of the matches, and look at the corresponding average_x. \n",
    "As you can See, average_x oscillates between two different values, which corresponds perfectly to if the features are found on the floor or on the tracker. \n",
    "\n",
    "When it is selecting features in the floor, it is finding them such that the average_x is negative. Because if you look at where the images are located, it is doing the locations of the second one minus locations of the first one. Giving a negative value. \n",
    "\n",
    "If however you look at when it locates features in the tracker sepparations. It is messing them up by an entire tracker, which makes it positive. \n",
    "\n",
    "*So what if I select it such that it chooses in between trackers, and minus the entire length of a tracker ? Could this work?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new idea\n",
    "\n",
    "Do the tracker sepparation detection, y que solo busque features en esas separaciones.\n",
    "\n",
    "Además, elegir solo la separación que esté mas a la derecha, para que así no cometa el error de centrarse en el putno que no es. \n",
    "\n",
    "\n",
    "Este método puede funcionar bastante bien. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
